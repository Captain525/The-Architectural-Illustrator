# The-Architectural-Illustrator

PROJECT OVERVIEW: 
    Use a Conditional GAN to generate real images of architecture from their outline/gradient. 


WHY USE CONDITIONAL GAN FOR THIS PROBLEM?
We want the model to "learn its own loss function". Essentially what this means is that we can avoid the difficult to quantify question of what "good" performance looks like, by saying good outputs would be indistinguishable from reality. 

This is why GANS are good for this type of problem, EVEN THOUGH the problem is supervised in nature. GANs learn a loss which classifies the output as real or fake, and simulatenously train a generative model to minimize the loss. Since they learn this "adaptive" loss, we can use the same structure for many different types of problems, rather than redesigning and rechoosing a loss for each specific function. 

GAN BASICS:
    A GAN is made up of essentially two "competing" models: A discriminator D, and a generator G. The role of the generator is to take in some sort of input (in the conditional gan case) and generate an output which somehow reflects that input, while also maintaining some form of randomness/stochasticity. The discriminator, on the other hand, is a classification model designed to classify an input as either "real" or "fake" ie generated by the generator. The "goal" of the generator is to trick the discriminator into thinking its generated images are real(thus signalling a "realistic" generated image), and the goal of the discriminator is to both correctly classify real input images as real, as well as spot the fakes passed in by the generator. 

    This idea is reflected in their respective loss functions. In the original GAN paper(1): they use the binary crossentropy loss for both models. That is, they take the negative log likelihood of each possible class and sum them up. 

    LD = -log(D(x)) - log(1-D(G(z)))
    LG = -log(D(G(z)))

    As you can see, for LD, D performs best with D(x) close to 1(correct on real) and D(z) close to 0, which would mean that log(D(x)) and log(1-D(z)) are close to zero (instead of negative) and taking the negative of the result means that the minimum possible loss represents the optimal values for D(x) and D(z).  

    For LG, it's slightly more complicated, as technically, we wish to minimize log(1-D(z)), since we want D(z) to be near 1 (signifying the generator tricked the discriminator), and thus that would mean we want the log(1-D(z)) to approach -inf. However, paper (1) mentions that early in training, D overpowers G, and the gradient of this loss function is too small to learn effectively, and the generator never improvces. So, instead of using that loss function, they instead propose to MAXIMIZE log(D(z)), essentially saying the same thing. And, that is equivalent to MINIMIZING -log(D(z)) which is where the loss function comes from. 

   The reason why these two models are coupled is based on the idea of improvmenet through competition: having a discriminator, or "opponent" to see through your flawed pictures makes you make better knockoffs, and having someone with better knockoffs forces you to improve your classification process. 

   Note that when we train the GAN, we don't update the two gradients simultaneously. In fact, we tried that early on in this process, but it had poor results. This makes sense, because when you update both gradients at once, each is basing their decision off the "previous" information, and will not be synced up in their outcomes. It's like two independent gradients almost. However, if you do the discriminator gradient first, THEN the generator, the generator can react to the gradient changes in the discriminator and learn from that. This is what is proposed in (1) as well. 


   CONDITIONAL GAN: 
        Note that for a normal GAN, the generator layer only takes in a noise distribution, ie a random vector in some latent space(just means hidden input space we can't see or interact with as users) as input. This is so all the outputs of the generator aren't identical. Essentially, what the learning process is doing in this case is assigning an output distribution to each vector in the latent space. So, when you get a certain random result, you get a given output. 

        However, in our problem we want the output to depend not only on randomness, but also on the image outline we pass in. Thus, we need to use a CONDITIONAL GAN instead. Paper (2) is the paper that proposes these nets, and fortunately they are very similar to normal GANS. 

        All we do in the conditional case is provide an extra input to both the generator and the discriminator, which is the condition. Thus, we take in both the condition and the randomness as input in the generator, and we take in both generated/real images as well as the condition in the discriminator. The ways to implement this vary, but often we concatenate it to the noise/input images. 

        However, one downside of this is that in more complicated models, the generator can learn to IGNORE the noise, and instead just use the condition. This problem is described in (3). To get around this, they implement the Dropout layers to simulate this randomness. However, they said this wasn't THAT effective, and we will attempt to find a way to remedy this. 

MODEL STRUCTURE:
    We use the structure proposed in (3) which uses a UNet architecture for the generator, and uses a PatchGAN model for the classifier. 








    

