{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YfIk2es3hJEd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "from skimage.util import img_as_float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bXp36NAVsUE",
        "outputId": "f8ed659c-aae5-4e57-89e8-8a59054fdd43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q8DzkUQdhZ6q"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Defines a block used in the UNET and PatchGAN architectures. \n",
        "    It consists of a Conv2D layer with kernel size 4 and stride 2, then followed by batchNorm, maybe dropout, then RELU. \n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, numFilters, BN, Dropout):\n",
        "        super().__init__()\n",
        "        self.kernel_size = (4,4)\n",
        "        self.BN = BN\n",
        "        self.Dropout = Dropout\n",
        "        self.stride= (2,2)\n",
        "        self.numFilters = numFilters\n",
        "\n",
        "        #WHICH PADDING TO USE?????\n",
        "        self.padding = \"same\"\n",
        "        kernelInitializer = tf.keras.initializers.RandomNormal(mean=0, stddev = .02)\n",
        "        self.conv = tf.keras.layers.Conv2D(numFilters, self.kernel_size, self.stride, padding = self.padding, kernel_initializer = kernelInitializer)\n",
        "        self.batchNorm = tf.keras.layers.BatchNormalization()\n",
        "        self.dropout = tf.keras.layers.Dropout(.5)\n",
        "        self.relu = tf.keras.layers.LeakyReLU(.2)\n",
        "\n",
        "    def call(self, input):\n",
        "        \n",
        "        batchSize, height, width, numChannels = input.shape\n",
        "        convOutput = self.conv(input)\n",
        "        newHeight, newWidth = self.calcShape(height, width)\n",
        "       \n",
        "        assert(convOutput.shape == (batchSize, newHeight, newWidth, self.numFilters))\n",
        "        if(self.BN):\n",
        "            convOutput = self.batchNorm(convOutput)\n",
        "        if(self.Dropout):\n",
        "            convOutput = self.dropout(convOutput)\n",
        "        activated = self.relu(convOutput)\n",
        "        return activated\n",
        "\n",
        "    def calcShape(self, height, width):\n",
        "        \"\"\"\n",
        "        Calculates the shape of the output of this layer given the input shape. \n",
        "        \"\"\"\n",
        "        fh, fw = self.kernel_size            ## filter height & width\n",
        "        sh, sw = self.stride       ## filter stride\n",
        "        # Cleaning padding input.\n",
        "        ry = height%sh\n",
        "        rx = width %sw\n",
        "        if(self.padding == \"same\"):\n",
        "            valueHeight = fh- ry - sh*int(not ry)\n",
        "            heightPad = max(valueHeight, 0)\n",
        "            #same here. \n",
        "            valueWidth = fw-rx -sw*int(not rx)\n",
        "            widthPad = max(valueWidth, 0)\n",
        "            #heightPad and width pad are total amount you should pad, so get left and right pad here. \n",
        "        else:\n",
        "            heightPad, widthPad = 0,0\n",
        "        outputHeight = (height + heightPad - fh)//sh + 1\n",
        "        outputWidth = (width + widthPad - fw)//sw + 1\n",
        "        return outputHeight, outputWidth\n",
        "class ConvTBlock(ConvBlock):\n",
        "    def __init__(self, numFilters, BN, Dropout):\n",
        "        super().__init__(numFilters, BN, Dropout)\n",
        "        #only one thing renamed. \n",
        "        #no output padding gets the right results. \n",
        "        kernelInitializer = tf.keras.initializers.RandomNormal(mean = 0, stddev = .02)\n",
        "        self.conv = tf.keras.layers.Conv2DTranspose(numFilters, self.kernel_size, self.stride, padding = self.padding,  kernel_initializer = kernelInitializer)\n",
        "    \"\"\"\n",
        "    def call(self, input):\n",
        "        \n",
        "        batchSize, height, width, numChannels = input.shape\n",
        "        convOutput = self.conv(input)\n",
        "        newHeight, newWidth = self.calcShape(height, width)\n",
        "       \n",
        "        assert(convOutput.shape == (batchSize, newHeight, newWidth, self.numFilters))\n",
        "        if(self.BN):\n",
        "            convOutput = self.batchNorm(convOutput)\n",
        "        if(self.Dropout):\n",
        "            convOutput = self.dropout(convOutput)\n",
        "        activated = self.relu(convOutput)\n",
        "        return activated\n",
        "    \"\"\"\n",
        "    def calcShape(self, height, width):\n",
        "        \"\"\"\n",
        "        Calculates shape of layer output in this case, it's different than the ConvBlock class. \n",
        "        \"\"\"\n",
        "        #in case of same padding. In reality more complicated than this, but can't figure it out rn. \n",
        "        shape = (self.stride[0]*height, self.stride[1]*width)\n",
        "        return shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CVXoRPdDGw8I"
      },
      "outputs": [],
      "source": [
        "class UNet(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    UNET is a potential choice for the Generator Architecture as posed by the paper. \n",
        "    It's an encoder-decoder architecture with skip connections between layer i in the encoder and layer n-i in the decoder. \n",
        "    They concatenate activations from layer i to layer n-i. \n",
        "    Ck = Convolution BatchNorm LeakyRelu layer with k filters. With the D, it means dropout of 50%. \n",
        "    All convolutions 4x4 spatial filters with stride 2. \n",
        "    Convolutions in encoder - downsample by factor of 2. In encoder they updsample by a factor of 2. \n",
        "    The encoder structure is: \n",
        "    C64-C128-C256-C512-C512-C512-C512-C512\n",
        "    The decoder structure is: \n",
        "    CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encblock1 = ConvBlock(64, False, False)\n",
        "        self.encblock2 = ConvBlock(128, True, False)\n",
        "        self.encblock3 = ConvBlock(256, True, False)\n",
        "        self.encblock4 = ConvBlock(512, True, False)\n",
        "        self.encblock5 = ConvBlock(512, True, False)\n",
        "        self.encblock6 = ConvBlock(512, True, False)\n",
        "        self.encblock7 = ConvBlock(512, True, False)\n",
        "        self.encblock8 = ConvBlock(512, True, False)\n",
        "\n",
        "        self.decblock1 = ConvTBlock(512, True, True)\n",
        "        self.decblock2 = ConvTBlock(1024, True, True)\n",
        "        self.decblock3 = ConvTBlock(1024, True, True)\n",
        "        self.decblock4 = ConvTBlock(1024, True, False)\n",
        "        self.decblock5 = ConvTBlock(1024, True, False)\n",
        "        self.decblock6 = ConvTBlock(512, True, False)\n",
        "        self.decblock7 = ConvTBlock(256, True, False)\n",
        "        self.decblock8 = ConvTBlock(128, True, False)\n",
        "        #I think this is right. \n",
        "        \n",
        "    def call(self, input):\n",
        "        \"\"\"\n",
        "        Include residual connections with the encoder blocks in the decoder. \n",
        "        Want connections between layer i and layer n-i. So, layer 7 and 9, 6 and 10 etc. Concatenate along the channels axis. \n",
        "        \"\"\"\n",
        "        #print(\"UNET input shape: \", input.shape)\n",
        "        block1 = self.encblock1(input)\n",
        "        #print(\"UNET block 1 shape: \", block1.shape)\n",
        "        block2 = self.encblock2(block1)\n",
        "        #print(\"UNET block 2 shape: \", block2.shape)\n",
        "        block3 = self.encblock3(block2)\n",
        "        #print(\"UNET block 3 shape: \", block3.shape)\n",
        "        block4 = self.encblock4(block3)\n",
        "        #print(\"UNET block 4 shape: \", block4.shape)\n",
        "        block5 = self.encblock5(block4)\n",
        "        #print(\"UNET block 5 shape: \", block5.shape)\n",
        "        block6 = self.encblock6(block5)\n",
        "        #print(\"UNET block 6 shape: \", block6.shape)\n",
        "        block7 = self.encblock7(block6)\n",
        "        #print(\"UNET block 7 shape: \", block7.shape)\n",
        "        block8 = self.encblock8(block7)\n",
        "        #print(\"UNET block 8 shape: \", block8.shape)\n",
        "\n",
        "        #finished encoder. \n",
        "        block9 = self.decblock1(block8)\n",
        "        #print(\"UNET block 9 shape: \", block9.shape)\n",
        "        #I think we want to do 7 and 16-7 = 9\n",
        "        combinedBlock9 = tf.concat([block7, block9], axis=-1)\n",
        "        block10 = self.decblock2(combinedBlock9)\n",
        "        #print(\"UNET block 10 shape: \", block10.shape)\n",
        "        combinedBlock10 = tf.concat([block6, block10], axis=-1)\n",
        "        block11 = self.decblock3(combinedBlock10)\n",
        "        #print(\"UNET block 11 shape: \", block11.shape)\n",
        "        combinedBlock11 = tf.concat([block5, block11], axis=-1)\n",
        "        block12 = self.decblock4(combinedBlock11)\n",
        "        #print(\"UNET block 12 shape: \", block12.shape)\n",
        "        combinedBlock12 = tf.concat([block4, block12], axis=-1)\n",
        "        block13 = self.decblock5(combinedBlock12)\n",
        "        #print(\"UNET block 13 shape: \", block13.shape)\n",
        "        combinedBlock13 = tf.concat([block3, block13], axis=-1)\n",
        "        block14 = self.decblock6(combinedBlock13)\n",
        "        #print(\"UNET block 14 shape: \", block14.shape)\n",
        "        combinedBlock14 = tf.concat([block2, block14], axis=-1)\n",
        "        block15 = self.decblock7(combinedBlock14)\n",
        "        #print(\"UNET block 15 shape: \", block15.shape)\n",
        "        combinedBlock15 = tf.concat([block1, block15], axis=-1)\n",
        "        block16 = self.decblock8(combinedBlock15)\n",
        "        #print(\"UNET block 16 shape: \", block16.shape)\n",
        "\n",
        "        #block16 is the output of the UNET, but we add a thing at the end of it as well. \n",
        "        \n",
        "        return block16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KbiDIvyb2gi2"
      },
      "outputs": [],
      "source": [
        "class EncDec(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encblock1 = ConvBlock(64, False, False)\n",
        "        self.encblock2 = ConvBlock(128, True, False)\n",
        "        self.encblock3 = ConvBlock(256, True, False)\n",
        "        self.encblock4 = ConvBlock(512, True, False)\n",
        "        self.encblock5 = ConvBlock(512, True, False)\n",
        "        self.encblock6 = ConvBlock(512, True, False)\n",
        "        self.encblock7 = ConvBlock(512, True, False)\n",
        "        self.encblock8 = ConvBlock(512, True, False)\n",
        "\n",
        "        self.decblock1 = ConvTBlock(512, True, True)\n",
        "        self.decblock2 = ConvTBlock(512, True, True)\n",
        "        self.decblock3 = ConvTBlock(512, True, True)\n",
        "        self.decblock4 = ConvTBlock(512, True, False)\n",
        "        self.decblock5 = ConvTBlock(512, True, False)\n",
        "        self.decblock6 = ConvTBlock(256, True, False)\n",
        "        self.decblock7 = ConvTBlock(64, True, False)\n",
        "       \n",
        "    def call(self, input):\n",
        "        block1 = self.encblock1(input)\n",
        "        block2 = self.encblock2(block1)\n",
        "        block3 = self.encblock3(block2)\n",
        "        block4 = self.encblock4(block3)\n",
        "        block5 = self.encblock5(block4)\n",
        "        block6 = self.encblock6(block5)\n",
        "        block7 = self.encblock7(block6)\n",
        "        block8 = self.encblock8(block7)\n",
        "\n",
        "        #finished encoder. \n",
        "        block9 = self.decblock1(block8)\n",
        "        #I think we want to do 7 and 16-7 = 9\n",
        "      \n",
        "        block10 = self.decblock2(block9)\n",
        "      \n",
        "        block11 = self.decblock3(block10)\n",
        "\n",
        "        block12 = self.decblock4(block11)\n",
        "    \n",
        "        block13 = self.decblock5(block12)\n",
        "       \n",
        "        block14 = self.decblock6(block13)\n",
        "      \n",
        "        block15 = self.decblock7(block14)\n",
        "\n",
        "        return block15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4nVAO7FJhIjb"
      },
      "outputs": [],
      "source": [
        "class Generator(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Generator for the GAN. \n",
        "    We want to find a way to increase the stochasticity of outputs. The paper used dropout to simulate randomness, but \n",
        "    it isn't very random. However, they found that the network learns to IGNORE the input noise. we need a way to make the input noise more \n",
        "    prominent. \n",
        "    \"\"\"\n",
        "    def __init__(self, reg_coeff):\n",
        "        super().__init__()\n",
        "        self.u = True\n",
        "        self.l1 = False\n",
        "        if(self.u):\n",
        "          self.UNet = UNet()\n",
        "        else:\n",
        "          self.UNet = EncDec()\n",
        "        #Regularization coefficient for L1 loss. \n",
        "        self.reg_coeff = reg_coeff\n",
        "        if self.u:\n",
        "          self.lastConvolution = tf.keras.layers.Conv2D(3, (4,4), (1,1), padding = \"same\", activation = \"tanh\")\n",
        "        else:\n",
        "          self.lastConvolution = tf.keras.layers.Conv2DTranspose(3, (4,4), (2,2), padding = \"same\", activation = \"tanh\")\n",
        "        #range -1 to 1. \n",
        "        self.tanh = tf.keras.activations.tanh\n",
        "    def call(self, data, training):\n",
        "        \n",
        "        batchSize, height, width, numChannels = data.shape\n",
        "        uNetOutput = self.UNet(data)\n",
        "        if self.u:\n",
        "          assert(uNetOutput.shape == (batchSize, height, width, 128))\n",
        "        else:\n",
        "          assert(uNetOutput.shape == (batchSize, int(height/2), int(width/2), 64))\n",
        "        generated = self.lastConvolution(uNetOutput)\n",
        "        print(generated.shape)\n",
        "        print(data.shape)\n",
        "        assert(generated.shape == (batchSize, height, width, 3))\n",
        "      \n",
        "        \n",
        "        assert(generated.shape[0:3] == data.shape[0:3])\n",
        "        return generated\n",
        "\n",
        "    def compute_loss(self, combined,  genPred, genReal, sample_weight=None):\n",
        "        \"\"\"\n",
        "        Want binary crossentropy with L1 regularization. \n",
        "        \"\"\"\n",
        "        generated = combined[0]\n",
        "        x = combined[1]\n",
        "        difference = generated-x\n",
        "        realY = tf.cast(tf.logical_not(tf.cast(0*genPred, bool)), tf.int32)\n",
        "        #calls the loss function passed into the compiler. \n",
        "        lossDefault = self.compiled_loss(realY, genPred, sample_weight)\n",
        "        #penalty gets a scalar value instead of a batchSize tensor. \n",
        "        l1 = tf.reduce_sum(tf.abs(difference), axis = [1,2,3])\n",
        "        if self.l1:\n",
        "          return lossDefault + self.reg_coeff*l1\n",
        "        else:\n",
        "          return lossDefault"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8Jp1hjEAGmXI"
      },
      "outputs": [],
      "source": [
        "class PatchGAN(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Layer called from the discriminator model. Pretty much does all the work of the discriminator though. Could make this a model. \n",
        "    Basically performs classification on each patch of the input image as real or fake. Then, you calculate the loss over that grid\n",
        "    instead of just one classification value. \n",
        "    \"\"\"\n",
        "    def __init__(self, size):\n",
        "        super().__init__()\n",
        "        #assuming we have a (size,size) discriminator\n",
        "\n",
        "        #FORMULA FOR RECEPTIVE FIELD SIZE: \n",
        "        #r = sum l= 1 to L (kl-1)*Prod i = 1 to l-1 (si) + 1\n",
        "        #for our example, since kl = 4, si = 2 for all layers except the last, and\n",
        "        \n",
        "        #specifically for a model structure like this, with n -1 conv blocks of (4,4) and 2 stride, \n",
        "        #and one final layer of stride 1 kernel 4, the formula is: \n",
        "        # r = -2 + 9*2^(L-2)\n",
        "        \n",
        "        self.conv1 = ConvBlock(64, False, False)\n",
        "        self.conv2 = ConvBlock(128, True, False)\n",
        "\n",
        "        \"\"\"\n",
        "        #add this if want 70x70 patch gan. \n",
        "        #self.conv3 = ConvBlock(256, True, False)\n",
        "        #self.conv4 = ConvBlock(512, True, False)\n",
        "        \"\"\"\n",
        "        kernelInitializer = tf.keras.initializers.RandomNormal(mean= 0, stddev = .02)\n",
        "        #forgot a padding = same on first run\n",
        "        self.lastConvLayer = tf.keras.layers.Conv2D(1, kernel_size = (4,4), strides = (2,2), padding = \"same\", activation = \"sigmoid\", kernel_initializer=kernelInitializer)\n",
        "    def call(self, input):\n",
        "        #print(\"PG input shape: \", input.shape)\n",
        "        output = self.conv1(input)\n",
        "        #print(\"PG layer1 shape: \", layer1.shape)\n",
        "        output = self.conv2(output)\n",
        "        \"\"\"\n",
        "        #add this if want 70x70 patch gan. \n",
        "        #print(\"PG layer2 shape: \", layer2.shape)\n",
        "        #layer3 = self.conv3(layer2)\n",
        "        #print(\"PG layer3 shape: \", layer3.shape)\n",
        "        #layer4 = self.conv4(layer3)\n",
        "        ##print(\"PG layer4 shape: \", layer4.shape)\n",
        "        \"\"\"\n",
        "\n",
        "        #this has the shape of batchSize x numPatches x numPatches x 1 \n",
        "        output = self.lastConvLayer(output)\n",
        "        #print(\"Output shape:  \", output.shape)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "izPyvPbGjKxC"
      },
      "outputs": [],
      "source": [
        "class NotAPatchGAN(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Layer called from the discriminator model. Pretty much does all the work of the discriminator though. Could make this a model. \n",
        "    Basically performs classification on each patch of the input image as real or fake. Then, you calculate the loss over that grid\n",
        "    instead of just one classification value. \n",
        "    \"\"\"\n",
        "    def __init__(self, size):\n",
        "        super().__init__()\n",
        "        #assuming we have a (size,size) discriminator\n",
        "\n",
        "        #FORMULA FOR RECEPTIVE FIELD SIZE: \n",
        "        #r = sum l= 1 to L (kl-1)*Prod i = 1 to l-1 (si) + 1\n",
        "        #for our example, since kl = 4, si = 2 for all layers except the last, and\n",
        "        \n",
        "        #specifically for a model structure like this, with n -1 conv blocks of (4,4) and 2 stride, \n",
        "        #and one final layer of stride 1 kernel 4, the formula is: \n",
        "        # r = -2 + 9*2^(L-2)\n",
        "        kernelInitializer = tf.keras.initializers.RandomNormal(mean= 0, stddev = .02)\n",
        "        self.conv1 = ConvBlock(64, False, False)\n",
        "        self.conv2 = ConvBlock(128, True, False)\n",
        "        self.lastConvLayer = tf.keras.layers.Conv2D(1, kernel_size = (4,4), strides = (2,2), padding = \"same\",  kernel_initializer=kernelInitializer)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense = tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
        "\n",
        "        \"\"\"\n",
        "        #add this if want 70x70 patch gan. \n",
        "        #self.conv3 = ConvBlock(256, True, False)\n",
        "        #self.conv4 = ConvBlock(512, True, False)\n",
        "        \"\"\"\n",
        "        \n",
        "\n",
        "    def call(self, input):\n",
        "        #print(\"PG input shape: \", input.shape)\n",
        "        output = self.conv1(input)\n",
        "        #print(\"PG layer1 shape: \", layer1.shape)\n",
        "        output = self.conv2(output)\n",
        "        \"\"\"\n",
        "        #add this if want 70x70 patch gan. \n",
        "        #print(\"PG layer2 shape: \", layer2.shape)\n",
        "        #layer3 = self.conv3(layer2)\n",
        "        #print(\"PG layer3 shape: \", layer3.shape)\n",
        "        #layer4 = self.conv4(layer3)\n",
        "        ##print(\"PG layer4 shape: \", layer4.shape)\n",
        "        \"\"\"\n",
        "        output = self.lastConvLayer(output)\n",
        "        #this has the shape of batchSize x numPatches x numPatches x 1 \n",
        "        output = self.flatten(output)\n",
        "        output = self.dense(output)\n",
        "        #print(\"Output shape:  \", output.shape)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qz1HK2SxGsiR"
      },
      "outputs": [],
      "source": [
        "class Discriminator(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.patch = True\n",
        "        if self.patch:\n",
        "          self.patchGAN = PatchGAN(16)\n",
        "        else:\n",
        "          self.patchGAN = NotAPatchGAN(16)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        \"\"\"\n",
        "        Integrated conditionality via concatenation. \n",
        "        \"\"\"\n",
        "        data = inputs[0]\n",
        "        condition = inputs[1]\n",
        "        #Concatenate the data to the condition to take both into account in the network. \n",
        "        concatenated = tf.concat([data, condition], axis=-1)\n",
        "        return self.patchGAN(concatenated)\n",
        "\n",
        "    def compute_loss(self, combined, predGen, predReal, sample_weights=None):\n",
        "        \"\"\"\n",
        "        Generates the labels and computes the loss. \n",
        "        Computes the two losses separately and then sums them together. \n",
        "        \"\"\"\n",
        "        #these aren't really used here. \n",
        "        generated = combined[0]\n",
        "        x = combined[1]\n",
        "        #generate the labels here instead of earlier before. \n",
        "        if(self.patch):\n",
        "          assert(predGen.shape == (generated.shape[0], 32, 32, 1))\n",
        "        else:\n",
        "          assert(predGen.shape == (generated.shape[0], 1))\n",
        "        realLabels = tf.cast(tf.logical_not(tf.cast(0*predReal, bool)), tf.int32)\n",
        "        genLabels = tf.cast(0*predGen, tf.int32)\n",
        "\n",
        "        realLoss = self.compiled_loss(realLabels, predReal, sample_weights)\n",
        "        genLoss = self.compiled_loss(genLabels, predGen, sample_weights)\n",
        "        return realLoss+genLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NYuE_fnCGjbR"
      },
      "outputs": [],
      "source": [
        "class GAN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        reg_coeff = 100\n",
        "        self.generator = Generator(reg_coeff = reg_coeff)\n",
        "        self.discriminator = Discriminator()\n",
        "\n",
        "    def call(self, data, training):\n",
        "        X = data[0]\n",
        "        Y = data[1]\n",
        "        #generate data\n",
        "        generated = self.generator(Y, training) \n",
        "        #run discriminator on generated examples. \n",
        "        genPred = self.discriminator((generated, Y))\n",
        "        #in case where want gradients of generator, don't need this. \n",
        "        realPred = None\n",
        "        #in case where you're calculating gradients of discriminator, run the real predictions. \n",
        "        if(X is not None):\n",
        "            #run discriminator on real examples. \n",
        "            realPred = self.discriminator((X, Y))\n",
        "        #return generated examples, predictions of generated examples, and predictions of real examples\n",
        "        return generated, genPred, realPred\n",
        "    \n",
        "    def batch_step(self, data, training):\n",
        "        \"\"\"\n",
        "        Called from both train step and test step, makes the methods simpler by keeping all the code in one place. \n",
        "        X - real examples of images. \n",
        "        Y - outlines of those specific real examples. This is the conditional input. \n",
        "        \"\"\"\n",
        "        X = data[0]\n",
        "        Y = data[1]\n",
        "        #print(\"batch step eager? :\",tf.executing_eagerly())\n",
        "        #calculate discriminator gradients first. \n",
        "        with tf.GradientTape() as disTape: \n",
        "            #forward pass. \n",
        "            generated, predGen, predReal= self(data, training)\n",
        "            discriminatorLoss = self.discriminator.compute_loss((generated, X), predGen, predReal)\n",
        "            self.dLoss.update_state(discriminatorLoss)\n",
        "        if(training):\n",
        "            #if training, calculate gradients and update weights. \n",
        "            disGrad = disTape.gradient(discriminatorLoss, self.discriminator.trainable_variables)\n",
        "            self.discriminator.optimizer.apply_gradients(zip(disGrad, self.discriminator.trainable_variables))\n",
        "        #now once those are updated, calculate generator weights. \n",
        "        with tf.GradientTape() as genTape:\n",
        "            #none indicates to the call function we're working with the generator. \n",
        "            generated, genPredict, predReal = self((None, Y), training)\n",
        "            #is there a way to make this better? \n",
        "            assert(predReal is None)\n",
        "            #calculate the loss of the generator. Don't need real predictions. \n",
        "            generatorLoss = self.generator.compute_loss((generated, X), genPredict, predReal)\n",
        "            self.gLoss.update_state(generatorLoss)\n",
        "        if(training):\n",
        "            print(\"about to update gradients\")\n",
        "            genGrad = genTape.gradient(generatorLoss, self.generator.trainable_variables)\n",
        "            self.generator.optimizer.apply_gradients(zip(genGrad, self.generator.trainable_variables))\n",
        "        self.updateStates(not training, generatorLoss, discriminatorLoss)\n",
        "        print(\"end of batch step\")\n",
        "        return self.evalMetrics(training)\n",
        "\n",
        "    def compile(self, optimizerGen, optimizerDis, lossFxnGen, lossFxnDis, metrics = None, steps_per_execution = 1):\n",
        "\n",
        "        super().compile(steps_per_execution = steps_per_execution, metrics = metrics)\n",
        "        self.generator.compile(optimizerGen, lossFxnGen)\n",
        "        self.discriminator.compile(optimizerDis, lossFxnDis)\n",
        "        #maybe add metrics here. \n",
        "        #self.createMetrics()\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        return self.batch_step(data, True)\n",
        "    @tf.function\n",
        "    def test_step(self, data):\n",
        "        return self.batch_step(data, False)\n",
        "\n",
        "    def generateImages(self, Y):\n",
        "        \"\"\"\n",
        "        Generate some images from the conditions. \n",
        "        \"\"\"\n",
        "        generated = self.generator(Y, training = False)\n",
        "        return generated\n",
        "    def createMetrics(self):\n",
        "        self.dLoss = tf.keras.metrics.Mean(name = \"dLoss\")\n",
        "        self.gLoss = tf.keras.metrics.Mean(name = \"gLoss\")\n",
        "        self.sumLoss = tf.keras.metrics.Mean(name = \"sumLoss\")\n",
        "        self.dValLoss = tf.keras.metrics.Mean(name = \"valDLoss\")\n",
        "        self.gValLoss = tf.keras.metrics.Mean(name = \"valGLoss\")\n",
        "        self.valSumLoss = tf.keras.metrics.Mean(name = \"valSumLoss\")\n",
        "    \n",
        "        self.listMetricsTrain = [self.dLoss, self.gLoss, self.sumLoss]\n",
        "        self.listMetricsTest = [self.dValLoss, self.gValLoss, self.valSumLoss]\n",
        "        self.listMetrics = self.listMetricsTrain + self.listMetricsTest\n",
        "        return self.listMetrics\n",
        "    def updateStates(self, val, gLoss, dLoss):\n",
        "        if val:\n",
        "            self.dValLoss.update_state(dLoss)\n",
        "            self.gValLoss.update_state(gLoss)\n",
        "            self.valSumLoss.update_state(dLoss+gLoss)\n",
        "\n",
        "        else:\n",
        "            self.dLoss.update_state(dLoss)\n",
        "            self.gLoss.update_state(gLoss)\n",
        "            self.sumLoss.update_state(dLoss + gLoss)\n",
        "    def resetStates(self):\n",
        "        for metric in self.listMetrics:\n",
        "            metric.reset_state()\n",
        "    def evalMetrics(self, training):\n",
        "        if training:\n",
        "            return self.evalMetricsTrain()\n",
        "        else:\n",
        "            return self.evalMetricsTest()\n",
        "    def evalMetricsTest(self):\n",
        "        return {metric.name:metric.result() for metric in self.listMetricsTest}\n",
        "    def evalMetricsTrain(self):\n",
        "        return {metric.name:metric.result() for metric in self.listMetricsTrain}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "z5U1ew7elKR5"
      },
      "outputs": [],
      "source": [
        "class displayImages(tf.keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Callback designed to display the real images, the edge images, the generated images from teh edge images, \n",
        "    and the result of the patchGAN discriminator. \n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, trainData,trainEdges, testData, testEdges):\n",
        "        self.trainData = trainData\n",
        "        self.trainEdges = trainEdges\n",
        "        self.testData = testData\n",
        "        self.testEdges = testEdges\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs):\n",
        "        return\n",
        "       \n",
        "    def on_epoch_end(self, batch, logs):\n",
        "        self.displayImages(batch, logs)\n",
        "        return \n",
        "    def displayImages(self, batch, logs):\n",
        "        print(\"in callback\")\n",
        "        numExamples = 5\n",
        "        trainImages = self.testData[0:numExamples]\n",
        "        trainEdges = self.testEdges[0:numExamples]\n",
        "        generatedTrainImages, genPredictions, realPredictions= self.model((trainImages, trainEdges), training = False)\n",
        "        if(len(realPredictions.shape)<=2):\n",
        "          doReal = False\n",
        "        else:\n",
        "          doReal = True\n",
        "          realPredictions = tf.tile(realPredictions, multiples = [1, 1, 1, 3])\n",
        "          genPredictions = tf.tile(genPredictions, multiples = [1, 1, 1, 3])\n",
        "        \n",
        "        trainEdgesTiled = tf.tile(trainEdges, multiples = [1, 1, 1, 3])\n",
        "        print(trainEdgesTiled.shape)\n",
        "        stackedImages = tf.stack([trainImages, trainEdgesTiled, generatedTrainImages], axis=0)\n",
        "        assert(stackedImages.shape == (3, numExamples, 256,256, 3))\n",
        "        \n",
        "        rows = numExamples\n",
        "        columns = 5\n",
        "        fig = plt.figure(figsize=(10, 10))\n",
        "        #print(\"start iteration\")\n",
        "        for i in range(0, numExamples):\n",
        "            #print(\"on i: \", i)\n",
        "            for j in range(columns-2):\n",
        "                #print(\"on j \", j)\n",
        "                index = i*columns + j + 1\n",
        "                fig.add_subplot(rows, columns, index)\n",
        "                plt.imshow(stackedImages[j, i, :], aspect = 'auto')  \n",
        "                plt.axis('off')\n",
        "                predProbability = 0\n",
        "                if(j == 0):\n",
        "                    predProbability = tf.reduce_mean(realPredictions[i])\n",
        "                elif(j == 2):\n",
        "                    predProbability = tf.reduce_mean(genPredictions[i])\n",
        "\n",
        "            if(doReal):\n",
        "              #print(\"on j \" , 3)\n",
        "              fig.add_subplot(rows,columns, i*columns + 4)\n",
        "              plt.imshow(realPredictions[i], aspect = 'auto')\n",
        "              plt.axis('off')\n",
        "       \n",
        "              #print(\"on j \", 4)\n",
        "              fig.add_subplot(rows,columns, i*columns + 5)\n",
        "              plt.imshow(genPredictions[i], aspect = 'auto')\n",
        "              plt.axis('off')\n",
        "         \n",
        "        plt.subplots_adjust(hspace=0, wspace = 0)\n",
        "        plt.show()\n",
        "        print(\"done callback\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WeNs16S8efo0"
      },
      "outputs": [],
      "source": [
        "# runModel.py\n",
        "\n",
        "def showImages(images):\n",
        "    for image in images:\n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "\n",
        "def split(images, sketches):\n",
        "    print(\"in split\")\n",
        "    percentTrain = .8\n",
        "    numImages = images.shape[0]\n",
        "    numTrain = int(percentTrain*numImages)\n",
        "    print(\"before numpy random\")\n",
        "    indices = np.random.permutation(numImages)\n",
        "    print(\"indices\")\n",
        "    mixedImages = images[indices]\n",
        "    #mixedImages = img_as_float(images[indices])\n",
        "    print(\"mixed images\")\n",
        "    mixedSketches = sketches[indices]\n",
        "    #mixedSketches = img_as_float(sketches[indices])\n",
        "    print(\"after imag sketches\")\n",
        "    trainImages = mixedImages[:numTrain]\n",
        "    trainSketches = mixedSketches[:numTrain]\n",
        "   \n",
        "    testImages = mixedImages[numTrain:]\n",
        "    testSketches = mixedSketches[numTrain:]\n",
        "    print(\"done split\")\n",
        "    return trainImages, trainSketches, testImages, testSketches\n",
        "\n",
        "\n",
        "def runModel(images, sketches):\n",
        "    print(\"got to run model\")\n",
        "    #maybe use a faster library method for this instead. \n",
        "    trainImages, trainSketches, testImages, testSketches = split(images, sketches)\n",
        "    #showImages(trainSketches[0:10])\n",
        "    learningRate = .0002\n",
        "    b1 = .5\n",
        "    b2 = .999\n",
        "    print(\"pre optimizers\")\n",
        "    #is giving half the learning rate the same as dividing the objective by 2? \n",
        "    optimizerDis = tf.keras.optimizers.Adam(learning_rate = learningRate, beta_1 = b1, beta_2 = b2)\n",
        "    optimizerGen = tf.keras.optimizers.Adam(learning_rate = learningRate, beta_1 = b1, beta_2 = b2)\n",
        "    \n",
        "    batchSize = 4\n",
        "    epochs = 40\n",
        "    lossFxn = tf.keras.losses.BinaryCrossentropy()\n",
        "    print(\"got to gan\")\n",
        "    model = GAN()\n",
        "    startCompAndBuild = time.time()\n",
        "    stepsPerExecution = 1\n",
        "    model.compile(optimizerGen, optimizerDis, lossFxn, lossFxn, metrics = model.createMetrics(), steps_per_execution = stepsPerExecution)\n",
        "    #need this for eager execution, without this it is automatically not eager. \n",
        "    #model.run_eagerly = True\n",
        "    model.build(input_shape = [(None, 256, 256, 3), (None, 256, 256, 1)])\n",
        "    endCompAndBuild = time.time()\n",
        "    compAndBuild = endCompAndBuild - startCompAndBuild\n",
        "    print(\"comp and build time: \", compAndBuild)\n",
        "    model.summary()\n",
        "    print(\"ready to train\")\n",
        "    smallerTrainImages = tf.constant(trainImages[:1000], dtype = tf.float32)\n",
        "    smallerTrainSketches = tf.constant(trainSketches[:1000], dtype = tf.float32)\n",
        "    smallerTestImages = tf.constant(testImages[:500], dtype = tf.float32)\n",
        "    smallerTestSketches = tf.constant(testSketches[:500], dtype = tf.float32)\n",
        "    saveFreq = 10\n",
        "    modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\"checkpoints/{epoch}weights\", monitor = \"sumLoss\",save_best_only = True,  mode = \"min\", save_weights_only = True, save_freq = saveFreq)\n",
        "    callbacks = [displayImages(smallerTrainImages, smallerTrainSketches, smallerTestImages, smallerTestSketches)]\n",
        "\n",
        "    history = model.fit(smallerTrainImages, smallerTrainSketches, batch_size = batchSize, epochs = epochs, validation_data = (smallerTestImages, smallerTestSketches), callbacks = callbacks)\n",
        "\n",
        "    generatedImages = model.generateImages(trainSketches[0:10])\n",
        "    showImages(generatedImages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OxD_lmKddmSo"
      },
      "outputs": [],
      "source": [
        "def randomJitter(images):\n",
        "    \"\"\"\n",
        "    Randomly jitters images, by increasing their size then cropping them. \n",
        "    Not sure if for loop is fastest way to do this. \n",
        "    \"\"\"\n",
        "    print(\"images shape: \", images.shape)\n",
        "    resizedImages = tf.image.resize(images, size = (286,286))\n",
        "    print(\"resized shape: \", resizedImages.shape)\n",
        "    listRandomCrop = []\n",
        "    for i in range(images.shape[0]):\n",
        "        randomCropping = tf.image.random_crop(resizedImages[i], (256,256, resizedImages.shape[-1]))\n",
        "        listRandomCrop.append(randomCropping)\n",
        "    croppedImages = tf.stack(listRandomCrop, axis=0)\n",
        "    return croppedImages.numpy().astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fDXDNOQAWigx"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/drive/My Drive/Architectural-Illustrator/DataCombined/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jqsmFOAAKXsx"
      },
      "outputs": [],
      "source": [
        "def load(image_file):\n",
        "  image = tf.io.read_file(image_file)\n",
        "  image = tf.io.decode_jpeg(image)\n",
        "\n",
        "  w = tf.shape(image)[1]\n",
        "  w = w // 2\n",
        "  input_image = image[:, w:, :]\n",
        "  input_image = np.expand_dims(input_image,2)\n",
        "  real_image = image[:, :w, :]\n",
        "\n",
        "  input_image = img_as_float(input_image)\n",
        "  real_image = img_as_float(real_image)\n",
        "\n",
        "  return input_image, real_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7tCRWUEqgy6z"
      },
      "outputs": [],
      "source": [
        "input_images = []\n",
        "real_images = []\n",
        "for i in range(69,600):\n",
        "  input_image, real_image = load(PATH + 'combine' + str(i) + '.jpg')\n",
        "  input_images.append(input_image[:,:,:,1])\n",
        "  real_images.append(real_image)\n",
        "input_images_ar = np.array(input_images)\n",
        "real_images_ar = np.array(real_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ9pdryZhwqD",
        "outputId": "c6f556a6-6d91-419d-a08a-a95c3887162d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(531, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "print(input_images_ar.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "CwY63nkuPg9G",
        "outputId": "c1c9c55b-389f-4d08-b237-6012f4b490e5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d250e37fd9cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images_ar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_images_ar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'runModel' is not defined"
          ]
        }
      ],
      "source": [
        "model = runModel(real_images_ar, input_images_ar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnbJfEAgii8K"
      },
      "outputs": [],
      "source": [
        "model = runModel(real_images_ar, input_images_ar)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "cs1430",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:50:36) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "ed9f322990000974222423e0dcb63d7b805f35bf78626c004e17d18311f929ca"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
